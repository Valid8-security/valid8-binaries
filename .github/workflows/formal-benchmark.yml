name: Formal Benchmark Suite

on:
  # Run weekly on Sunday at midnight
  schedule:
    - cron: '0 0 * * 0'
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      benchmark:
        description: 'Specific benchmark to run (leave empty for all)'
        required: false
        type: choice
        options:
          - all
          - owasp_benchmark
          - webgoat
          - railsgoat
          - nodegoat
          - dvwa

jobs:
  formal-benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2 hours max
    
    steps:
    - name: Checkout Parry
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        pip install gitpython
    
    - name: Install Ollama for AI scanning
      run: |
        curl -fsSL https://ollama.ai/install.sh | sh
        ollama serve &
        sleep 10
        ollama pull codellama:7b-instruct-q4_K_M
    
    - name: Create benchmark workspace
      run: |
        mkdir -p benchmark_workspace
    
    - name: Run formal benchmarks
      id: benchmark
      run: |
        if [ "${{ github.event.inputs.benchmark }}" = "all" ] || [ -z "${{ github.event.inputs.benchmark }}" ]; then
          python scripts/benchmark/formal_benchmark.py --workspace benchmark_workspace
        else
          python scripts/benchmark/formal_benchmark.py --workspace benchmark_workspace --benchmark ${{ github.event.inputs.benchmark }}
        fi
      continue-on-error: true
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: formal-benchmark-results-${{ github.run_number }}
        path: |
          benchmark_workspace/formal_benchmark_results.json
          benchmark_workspace/FORMAL_BENCHMARK_REPORT.md
        retention-days: 90
    
    - name: Generate benchmark badge
      run: |
        PRECISION=$(jq -r '.summary.avg_precision' benchmark_workspace/formal_benchmark_results.json | awk '{printf "%.0f", $1*100}')
        RECALL=$(jq -r '.summary.avg_recall' benchmark_workspace/formal_benchmark_results.json | awk '{printf "%.0f", $1*100}')
        
        echo "PRECISION=${PRECISION}%" >> $GITHUB_ENV
        echo "RECALL=${RECALL}%" >> $GITHUB_ENV
        
        echo "## Benchmark Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Precision**: ${PRECISION}%" >> $GITHUB_STEP_SUMMARY
        echo "- **Recall**: ${RECALL}%" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        cat benchmark_workspace/FORMAL_BENCHMARK_REPORT.md >> $GITHUB_STEP_SUMMARY
    
    - name: Comment on PR (if applicable)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const results = JSON.parse(fs.readFileSync('benchmark_workspace/formal_benchmark_results.json', 'utf8'));
          const summary = results.summary;
          
          const comment = `## ðŸ“Š Formal Benchmark Results
          
          | Metric | Result |
          |--------|--------|
          | **Precision** | ${(summary.avg_precision * 100).toFixed(1)}% |
          | **Recall** | ${(summary.avg_recall * 100).toFixed(1)}% |
          | **F1 Score** | ${summary.avg_f1_score.toFixed(3)} |
          | **Benchmarks** | ${summary.benchmarks_run} |
          
          <details>
          <summary>Detailed Results</summary>
          
          ${results.benchmarks.map(b => `
          ### ${b.benchmark_name} (${b.language})
          - Precision: ${(b.precision * 100).toFixed(1)}%
          - Recall: ${(b.recall * 100).toFixed(1)}%
          - F1 Score: ${b.f1_score.toFixed(3)}
          - Scan Duration: ${b.scan_duration.toFixed(2)}s
          `).join('\n')}
          
          </details>
          
          ${results.conclusions.map(c => `- ${c}`).join('\n')}
          `;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
    
    - name: Update benchmark badge (main branch only)
      if: github.ref == 'refs/heads/main'
      run: |
        # Create or update benchmark results file
        cp benchmark_workspace/formal_benchmark_results.json docs/benchmarks/latest_formal_results.json
        
        # Commit and push if there are changes
        git config --global user.name 'Parry Bot'
        git config --global user.email 'bot@parry.dev'
        git add docs/benchmarks/latest_formal_results.json
        git diff --quiet && git diff --staged --quiet || git commit -m "chore: Update benchmark results [skip ci]"
        git push || true
