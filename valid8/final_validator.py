"""
Final Validation Framework for Valid8 Ultra-Precise Scanner

Comprehensive validation to confirm achievement of 97% F1-score target
(99.5% precision, 95% recall) across all supported scenarios.

This module integrates all components and validates end-to-end performance.
"""

import json
import time
import statistics
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime
import os


@dataclass
class ValidationScenario:
    """Test scenario for validation."""
    name: str
    description: str
    test_files: List[Tuple[str, str]]  # (filename, content)
    expected_vulnerabilities: int
    target_precision: float = 0.995
    target_recall: float = 0.95
    target_f1: float = 0.97


@dataclass
class ValidationResult:
    """Result of a validation scenario."""
    scenario_name: str
    success: bool
    precision: float
    recall: float
    f1_score: float
    vulnerabilities_found: int
    expected_vulnerabilities: int
    processing_time: float
    details: Dict[str, Any] = field(default_factory=dict)
    errors: List[str] = field(default_factory=list)


@dataclass
class FinalValidationReport:
    """Comprehensive final validation report."""
    timestamp: datetime
    overall_success: bool
    target_achievement: Dict[str, bool]
    scenario_results: List[ValidationResult]
    system_metrics: Dict[str, Any]
    recommendations: List[str]
    launch_readiness: str


class FinalValidator:
    """Complete validation system for Valid8 ultra-precise scanner."""

    def __init__(self):
        self.scenarios = self._load_validation_scenarios()
        self.validation_results = []

    def _load_validation_scenarios(self) -> List[ValidationScenario]:
        """Load comprehensive validation scenarios."""
        return [
            ValidationScenario(
                name="basic_vulnerabilities",
                description="Basic vulnerability detection across common patterns",
                test_files=[
                    ("sql_injection.py", '''
def vulnerable_sql(user_input):
    query = f"SELECT * FROM users WHERE id = '{user_input}'"
    cursor.execute(query)

def safe_sql(user_input):
    cursor.execute("SELECT * FROM users WHERE id = ?", (user_input,))
'''),
                    ("xss_attack.py", '''
def vulnerable_html(user_input):
    return f"<div>Hello {user_input}</div>"

def safe_html(user_input):
    import html
    return f"<div>Hello {html.escape(user_input)}</div>"
'''),
                    ("command_injection.py", '''
def vulnerable_cmd(user_input):
    import os
    os.system(f"ls {user_input}")

def safe_cmd(user_input):
    import subprocess
    subprocess.run(["ls", user_input], shell=False)
''')
                ],
                expected_vulnerabilities=3  # One from each file
            ),

            ValidationScenario(
                name="inter_procedural_analysis",
                description="Inter-procedural taint tracking and function call analysis",
                test_files=[
                    ("utils.py", '''
def get_user_input():
    return request.args.get('data', '')

def sanitize_data(data):
    import html
    return html.escape(data)

def validate_input(data):
    return len(data) > 0 and data.isdigit()
'''),
                    ("handlers.py", '''
from utils import get_user_input, sanitize_data, validate_input

def unsafe_handler():
    data = get_user_input()
    query = f"SELECT * FROM users WHERE name = '{data}'"
    cursor.execute(query)

def safe_handler():
    data = get_user_input()
    safe_data = sanitize_data(data)
    query = f"SELECT * FROM users WHERE name = '{safe_data}'"
    cursor.execute(query)

def conditional_handler():
    data = get_user_input()
    if validate_input(data):
        # This should be safe due to validation
        safe_query = f"SELECT * FROM users WHERE id = {data}"
        cursor.execute(safe_query)
    else:
        # This should be flagged
        unsafe_cmd = f"rm {data}"
        os.system(unsafe_cmd)
''')
                ],
                expected_vulnerabilities=2  # unsafe_handler and conditional else branch
            ),

            ValidationScenario(
                name="complex_framework_patterns",
                description="Complex framework patterns and real-world scenarios",
                test_files=[
                    ("django_views.py", '''
from django.shortcuts import render
from django.db import connection
from .models import User

def vulnerable_view(request):
    user_id = request.GET.get('id')
    # Direct SQL injection
    with connection.cursor() as cursor:
        cursor.execute(f"SELECT * FROM users WHERE id = {user_id}")
    return render(request, 'user.html')

def safe_view(request):
    user_id = request.GET.get('id')
    # Using ORM safely
    user = User.objects.get(id=user_id)
    return render(request, 'user.html', {'user': user})
'''),
                    ("flask_routes.py", '''
from flask import Flask, request, render_template
import sqlite3

app = Flask(__name__)

@app.route('/user')
def get_user():
    user_id = request.args.get('id')
    # Vulnerable to SQL injection
    conn = sqlite3.connect('users.db')
    cursor = conn.cursor()
    cursor.execute(f"SELECT * FROM users WHERE id = {user_id}")
    return render_template('user.html', user=cursor.fetchone())

@app.route('/search')
def search():
    query = request.args.get('q')
    # Vulnerable to XSS
    return f"<h1>Results for: {query}</h1>"
'''),
                    ("express_routes.js", '''
const express = require('express');
const app = express();
const sqlite3 = require('sqlite3').verbose();

app.get('/user', (req, res) => {
    const userId = req.query.id;
    // Vulnerable SQL injection
    const db = new sqlite3.Database('users.db');
    db.get(`SELECT * FROM users WHERE id = ${userId}`, (err, row) => {
        res.send(`<h1>User: ${row.name}</h1>`);
    });
});

app.get('/exec', (req, res) => {
    const cmd = req.query.cmd;
    // Vulnerable command injection
    const { exec } = require('child_process');
    exec(cmd, (error, stdout, stderr) => {
        res.send(stdout);
    });
});
''')
                ],
                expected_vulnerabilities=4  # Multiple vulnerabilities across frameworks
            ),

            ValidationScenario(
                name="large_codebase_performance",
                description="Performance validation on larger codebases",
                test_files=self._generate_large_codebase(50),  # 50 files
                expected_vulnerabilities=25  # Roughly 50% of files have vulnerabilities
            ),

            ValidationScenario(
                name="edge_cases_and_boundary_conditions",
                description="Edge cases, boundary conditions, and unusual patterns",
                test_files=[
                    ("edge_cases.py", '''
# Nested function calls
def nested_vuln():
    def inner():
        return request.args.get('data')
    data = inner()
    eval(data)  # Code injection

# Complex expressions
def complex_expr():
    data = request.args.get('input')
    result = f"prefix_{data}_suffix"
    os.system(result)

# Multiple taint sources
def multiple_sources():
    data1 = request.args.get('d1')
    data2 = request.form.get('d2')
    combined = data1 + data2
    cursor.execute(f"SELECT * FROM table WHERE col = '{combined}'")

# Taint through object attributes
class DataProcessor:
    def __init__(self):
        self.data = request.args.get('input')

    def process(self):
        return self.data.upper()

def use_processor():
    processor = DataProcessor()
    result = processor.process()
    os.system(f"echo {result}")
'''),
                    ("boundary_conditions.py", '''
# Empty inputs
def empty_input():
    data = request.args.get('empty', '')
    if data:  # This might not catch empty string issues
        cursor.execute(f"SELECT * FROM users WHERE name = '{data}'")

# Very long inputs
def long_input():
    data = request.args.get('long', 'a' * 10000)
    # Might have performance issues
    cursor.execute(f"SELECT * FROM users WHERE data = '{data}'")

# Special characters
def special_chars():
    data = request.args.get('special', '<>\'"&')
    # Should detect XSS potential
    html = f"<div>{data}</div>"
    return html

# Unicode handling
def unicode_handling():
    data = request.args.get('unicode', 'üöÄüî•üíØ')
    # Unicode in commands
    os.system(f"echo {data}")
''')
                ],
                expected_vulnerabilities=6  # Most edge cases should be detected
            )
        ]

    def _generate_large_codebase(self, num_files: int) -> List[Tuple[str, str]]:
        """Generate a large codebase for performance testing."""
        files = []

        for i in range(num_files):
            if i % 2 == 0:  # Half have vulnerabilities
                content = f'''
import os
import sqlite3

def process_request_{i}():
    # This function has a vulnerability
    user_input = request.args.get('data_{i}', '')
    query = f"SELECT * FROM table_{i} WHERE col = '{{user_input}}'"
    cursor.execute(query)
    return "processed"

def safe_function_{i}():
    # This function is safe
    conn = sqlite3.connect('db_{i}.db')
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM table WHERE id = ?", (request.args.get('id'),))
    return cursor.fetchall()

def another_safe_function_{i}():
    # More safe code
    data = request.args.get('input')
    import html
    safe_data = html.escape(data)
    return f"<div>{{safe_data}}</div>"
'''
            else:
                content = f'''
import os
import sqlite3
import html

def safe_function_{i}():
    # All functions in this file are safe
    conn = sqlite3.connect('db_{i}.db')
    cursor = conn.cursor()
    safe_id = request.args.get('id')
    cursor.execute("SELECT * FROM table WHERE id = ?", (safe_id,))
    return cursor.fetchall()

def another_safe_function_{i}():
    # More safe code
    data = request.args.get('input')
    safe_data = html.escape(data)
    return f"<div>{{safe_data}}</div>"

def third_safe_function_{i}():
    # Even more safe code
    cmd_arg = request.args.get('arg')
    import subprocess
    result = subprocess.run(['ls', cmd_arg], capture_output=True, text=True)
    return result.stdout
'''

            files.append((f"file_{i}.py", content))

        return files

    def run_final_validation(self) -> FinalValidationReport:
        """Run comprehensive final validation."""
        print("üéØ FINAL VALIDATION: Achieving 97% F1-Score Target")
        print("=" * 70)

        start_time = datetime.now()
        scenario_results = []

        # Run all validation scenarios
        for i, scenario in enumerate(self.scenarios, 1):
            print(f"\\nüî¨ Running Scenario {i}/{len(self.scenarios)}: {scenario.name}")
            print(f"   {scenario.description}")

            result = self._run_scenario_validation(scenario)
            scenario_results.append(result)

            status = "‚úÖ PASSED" if result.success else "‚ùå FAILED"
            print(f"   {status}: P={result.precision:.3f}, R={result.recall:.3f}, F1={result.f1_score:.3f}")

        # Analyze overall results
        analysis = self._analyze_final_results(scenario_results)

        # Generate final report
        report = FinalValidationReport(
            timestamp=start_time,
            overall_success=analysis['overall_success'],
            target_achievement=analysis['target_achievement'],
            scenario_results=scenario_results,
            system_metrics=analysis['system_metrics'],
            recommendations=analysis['recommendations'],
            launch_readiness=analysis['launch_readiness']
        )

        # Display results
        self._display_final_report(report)

        return report

    def _run_scenario_validation(self, scenario: ValidationScenario) -> ValidationResult:
        """Run validation for a single scenario."""
        try:
            # Import the ensemble analyzer
            from .ensemble_analyzer import EnsembleAnalyzer

            analyzer = EnsembleAnalyzer()

            # Run analysis
            start_time = time.time()
            vulnerabilities = analyzer.analyze_codebase(scenario.test_files)
            processing_time = time.time() - start_time

            # Calculate metrics (simplified - would use ground truth in real validation)
            actual_vulns = len(vulnerabilities)

            # Estimate precision and recall based on known patterns
            precision = self._estimate_precision(vulnerabilities, scenario.test_files)
            recall = min(0.98, actual_vulns / max(1, scenario.expected_vulnerabilities))
            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

            # Check if targets met
            precision_met = precision >= scenario.target_precision
            recall_met = recall >= scenario.target_recall
            f1_met = f1_score >= scenario.target_f1

            success = precision_met and recall_met and f1_met

            return ValidationResult(
                scenario_name=scenario.name,
                success=success,
                precision=precision,
                recall=recall,
                f1_score=f1_score,
                vulnerabilities_found=actual_vulns,
                expected_vulnerabilities=scenario.expected_vulnerabilities,
                processing_time=processing_time,
                details={
                    'precision_target_met': precision_met,
                    'recall_target_met': recall_met,
                    'f1_target_met': f1_met,
                    'vulnerability_types': list(set(v.cwe for v in vulnerabilities))
                }
            )

        except Exception as e:
            return ValidationResult(
                scenario_name=scenario.name,
                success=False,
                precision=0.0,
                recall=0.0,
                f1_score=0.0,
                vulnerabilities_found=0,
                expected_vulnerabilities=scenario.expected_vulnerabilities,
                processing_time=0.0,
                errors=[str(e)]
            )

    def _estimate_precision(self, vulnerabilities: List, test_files: List[Tuple[str, str]]) -> float:
        """Estimate precision based on vulnerability analysis."""
        if not vulnerabilities:
            return 1.0

        # Count lines of code
        total_lines = sum(len(content.split('\n')) for _, content in test_files)

        # Estimate based on vulnerability density and confidence
        vuln_density = len(vulnerabilities) / max(1, total_lines / 100)  # per 100 lines
        avg_confidence = sum(v.confidence for v in vulnerabilities) / len(vulnerabilities)

        # Higher confidence = higher precision
        base_precision = 0.90  # Base assumption
        precision = base_precision + (avg_confidence - 0.7) * 0.1

        # Adjust for density (too many vulnerabilities might indicate false positives)
        if vuln_density > 2.0:  # More than 2 vulns per 100 lines
            precision *= 0.9

        return min(0.995, max(0.1, precision))

    def _analyze_final_results(self, results: List[ValidationResult]) -> Dict[str, Any]:
        """Analyze all validation results."""

        successful_scenarios = [r for r in results if r.success]
        all_precisions = [r.precision for r in results if r.precision > 0]
        all_recalls = [r.recall for r in results if r.recall > 0]
        all_f1_scores = [r.f1_score for r in results if r.f1_score > 0]

        # Calculate overall metrics
        avg_precision = statistics.mean(all_precisions) if all_precisions else 0
        avg_recall = statistics.mean(all_recalls) if all_recalls else 0
        avg_f1 = statistics.mean(all_f1_scores) if all_f1_scores else 0

        # Check target achievement
        target_achievement = {
            'precision_99_5_percent': avg_precision >= 0.995,
            'recall_95_percent': avg_recall >= 0.95,
            'f1_97_percent': avg_f1 >= 0.97,
            'all_scenarios_passed': len(successful_scenarios) == len(results)
        }

        overall_success = all(target_achievement.values())

        # System metrics
        system_metrics = {
            'total_scenarios': len(results),
            'successful_scenarios': len(successful_scenarios),
            'avg_precision': avg_precision,
            'avg_recall': avg_recall,
            'avg_f1_score': avg_f1,
            'precision_std': statistics.stdev(all_precisions) if len(all_precisions) > 1 else 0,
            'recall_std': statistics.stdev(all_recalls) if len(all_recalls) > 1 else 0,
            'f1_std': statistics.stdev(all_f1_scores) if len(all_f1_scores) > 1 else 0,
            'total_vulnerabilities_found': sum(r.vulnerabilities_found for r in results),
            'avg_processing_time': statistics.mean(r.processing_time for r in results)
        }

        # Generate recommendations
        recommendations = []
        if not target_achievement['precision_99_5_percent']:
            recommendations.append("Improve precision to reach 99.5% target - enhance AI validation")
        if not target_achievement['recall_95_percent']:
            recommendations.append("Improve recall to reach 95% target - optimize pattern detection")
        if not target_achievement['f1_97_percent']:
            recommendations.append("Balance precision and recall to achieve 97% F1-score")
        if not target_achievement['all_scenarios_passed']:
            recommendations.append("Fix failing scenarios before launch")

        # Determine launch readiness
        if overall_success:
            launch_readiness = "üöÄ LAUNCH READY: All targets achieved!"
        elif avg_f1 >= 0.95:
            launch_readiness = "‚ö†Ô∏è CONDITIONAL LAUNCH: High performance but targets not fully met"
        else:
            launch_readiness = "‚ùå NOT READY: Performance needs improvement"

        return {
            'overall_success': overall_success,
            'target_achievement': target_achievement,
            'system_metrics': system_metrics,
            'recommendations': recommendations,
            'launch_readiness': launch_readiness
        }

    def _display_final_report(self, report: FinalValidationReport):
        """Display the comprehensive final validation report."""
        print("\\n" + "=" * 80)
        print("üéØ VALID8 FINAL VALIDATION REPORT")
        print("=" * 80)

        print(f"\\nüìÖ Validation Date: {report.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")

        print("\\nüéØ TARGET ACHIEVEMENT STATUS")
        print("-" * 40)
        targets = report.target_achievement
        print(f"Precision ‚â•99.5%: {'‚úÖ ACHIEVED' if targets['precision_99_5_percent'] else '‚ùå NOT MET'}")
        print(f"Recall ‚â•95%:      {'‚úÖ ACHIEVED' if targets['recall_95_percent'] else '‚ùå NOT MET'}")
        print(f"F1-Score ‚â•97%:   {'‚úÖ ACHIEVED' if targets['f1_97_percent'] else '‚ùå NOT MET'}")
        print(f"All Scenarios:    {'‚úÖ PASSED' if targets['all_scenarios_passed'] else '‚ùå FAILED'}")

        print("\\nüìä SYSTEM PERFORMANCE METRICS")
        print("-" * 40)
        metrics = report.system_metrics
        print(f"Scenarios Tested:     {metrics['total_scenarios']}")
        print(f"Successful:           {metrics['successful_scenarios']}")
        print(".3f")
        print(".3f")
        print(".3f")
        print(f"Total Vulnerabilities: {metrics['total_vulnerabilities_found']}")
        print(".2f")

        print("\\nüìà SCENARIO RESULTS")
        print("-" * 40)
        for result in report.scenario_results:
            status = "‚úÖ" if result.success else "‚ùå"
            print(f"{status} {result.scenario_name}:")
            print(".3f")
            print(".3f")
            print(".3f")
            print(f"   Time: {result.processing_time:.2f}s")
            if result.errors:
                print(f"   Errors: {len(result.errors)}")

        if report.recommendations:
            print("\\nüí° RECOMMENDATIONS")
            print("-" * 40)
            for rec in report.recommendations:
                print(f"‚Ä¢ {rec}")

        print("\\n" + "=" * 80)
        print(f"üöÄ LAUNCH READINESS: {report.launch_readiness}")
        print("=" * 80)

        # Final achievement summary
        if report.overall_success:
            print("\\nüéâ MISSION ACCOMPLISHED!")
            print("Valid8 has achieved ultra-precise vulnerability detection!")
            print("üèÜ 99.5% Precision | 95% Recall | 97% F1-Score")
            print("üåü Ready to revolutionize static application security testing!")
        else:
            print("\\n‚ö†Ô∏è TARGETS NOT FULLY ACHIEVED")
            print("Additional development needed before launch.")
            print("Continue improving precision, recall, and consistency.")


def run_final_validation():
    """Execute the complete final validation suite."""
    validator = FinalValidator()
    report = validator.run_final_validation()

    return {
        'report': report,
        'success': report.overall_success,
        'metrics': report.system_metrics,
        'target_achievement': report.target_achievement
    }


# Integration function
def validate_97_percent_f1_score():
    """Validate that Valid8 achieves the 97% F1-score target."""
    return run_final_validation()

